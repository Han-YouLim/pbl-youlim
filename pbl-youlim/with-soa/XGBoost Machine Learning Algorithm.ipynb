{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "efdd4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b2a74719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리한 데이터들 불러오기.\n",
    "DATA_IN_PATH = '../../../big_data_sample/pbl/with_soa/'\n",
    "DATA_OUT_PATH = '../../../big_data_sample/pbl/with_soa/data_out/' \n",
    "train_data = pd.read_csv(DATA_IN_PATH+'real_train_data.csv', encoding='cp949',\n",
    "                 names=['comments', 'label'])\n",
    "test_data = pd.read_csv(DATA_IN_PATH+'real_test_data.csv', encoding='cp949',\n",
    "                 names=['comments', 'label'])\n",
    "RANDOM_SEED = 32\n",
    "TEST_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "aa4bae1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments =train_data['comments']\n",
    "labels = list(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "77f9d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 0.0, analyzer=\"char\", sublinear_tf=True, ngram_range=(1,3), max_features=5000) \n",
    "\n",
    "X = vectorizer.fit_transform(comments.values.astype('U'))\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "81e890f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "338c0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer(max_features=5000, encoding=\"utf-8\",  \n",
    "#       ngram_range = (1,3),  \n",
    "#       token_pattern = \"[A-Za-z_][A-Za-z\\d_]*\")\n",
    "# X = cv.fit_transform(data.title).toarray()\n",
    "# y = data['label']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "#       test_size=0.33, \n",
    "#       random_state=0)\n",
    "# count_df = pd.DataFrame(X_train, columns=cv.get_feature_names())\n",
    "\n",
    "# count_df['etiket'] = y_train\n",
    "# data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "5bd701eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\gksdb\\anaconda3\\envs\\ilovenlp\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:47:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "733cfa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6506"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f86f692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = test_data['label']\n",
    "test_comments = test_data['comments'].values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7866f1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = vectorizer.fit_transform(test_comments)\n",
    "test_y = np.array(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c4069018",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_X)\n",
    "predictions = [round(value) for value in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "79384906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.36%\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_y, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ecb748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14df8bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e4d1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
